{"paragraphs":[{"text":"import com.datastax.spark.connector._\nimport org.apache.spark.sql.cassandra._\nimport scala.util.Try\n","user":"anonymous","dateUpdated":"2018-02-20T11:26:01-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1519154725645_1951052652","id":"20180220-112525_1636082280","dateCreated":"2018-02-20T11:25:25-0800","dateStarted":"2018-02-20T11:26:01-0800","dateFinished":"2018-02-20T11:26:01-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2856"},{"title":"Copy one Cassandra Table to A New Table","text":"// Practice creating new tables from existing Dataframes\n\nval inputData = spark\n  .range(1, 100)\n  .select('id.as(\"k\"), 'id.as(\"c\"), 'id.as(\"v\"))\n  \n//Create a table\nTry(inputData.createCassandraTable(\"test\", \"source\", Some(Seq(\"k\")), Some(Seq(\"c\"))))\n\ninputData\n  .write\n  .cassandraFormat(\"tab\",\"test\")\n  .mode(\"append\")\n  .save()\n\n\n// Your Code Here\n\nspark.read.cassandraFormat(\"destination\", \"test\").load().count == 100 // Should be true :)","user":"anonymous","dateUpdated":"2018-02-20T11:37:30-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1519154343652_-2143579772","id":"20180220-111903_1686365766","dateCreated":"2018-02-20T11:19:03-0800","dateStarted":"2018-02-20T11:36:29-0800","dateFinished":"2018-02-20T11:36:30-0800","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2857"},{"title":"Use SQL to create a Cassandra Dataframe","text":"// Practice the SQL API\nval sql = \"\"\"Your SQL Here\"\"\"\n\nval df = spark.sql(sql).count == 100","user":"anonymous","dateUpdated":"2018-02-20T11:36:25-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1519154391163_1238816","id":"20180220-111951_705527584","dateCreated":"2018-02-20T11:19:51-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2858"},{"title":"Change the number of Partitions used in Spark","text":"// Can change the read parameters for a Dataframe reader?\nval df = spark.read.cassandraFormat(\"tab\", \"test\").load\n\nval originalPartitionCount = df.rdd.partitions.size\n\nval df2 = ???\n\nval newPartitionCount = df2.rdd.partitions.size\n\noriginalPartitionCount != newPartitionCount\ndf.count == df2.count","user":"anonymous","dateUpdated":"2018-02-20T11:37:48-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1519154907963_-1648432007","id":"20180220-112827_262208189","dateCreated":"2018-02-20T11:28:27-0800","dateStarted":"2018-02-20T11:35:58-0800","dateFinished":"2018-02-20T11:35:59-0800","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2859"},{"title":"Join Data from a CSV with Data in  Cassandra","text":"val inputData = spark\n  .range(1, 10)\n  .select('id.as(\"k\"))\n  \n// Write inputData to a local file file://something.csv\ninputData.write //??\n// Make a dataframe which reads from this file\nval dfFromFile = spark.read //?? \n// Make a dataframe which reads from our test.source Cassandra table\nval dfFromCassandra = spark.read //??\n// Join them together on column k\nval join = //??\n\njoin.count == 10","user":"anonymous","dateUpdated":"2018-02-20T11:42:31-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1519155176945_756246974","id":"20180220-113256_1239096648","dateCreated":"2018-02-20T11:32:56-0800","dateStarted":"2018-02-20T11:41:53-0800","dateFinished":"2018-02-20T11:41:53-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2860"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1519155528290_1599538297","id":"20180220-113848_526833318","dateCreated":"2018-02-20T11:38:48-0800","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2861"}],"name":"Spark Cassandra Challenges","id":"2D9MBAUH5","angularObjects":{"2D9MRXK9C:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}