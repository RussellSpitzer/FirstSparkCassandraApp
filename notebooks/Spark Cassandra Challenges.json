{"paragraphs":[{"text":"import com.datastax.spark.connector._\nimport org.apache.spark.sql.cassandra._\nimport scala.util.Try\n","user":"anonymous","dateUpdated":"2018-02-20T11:26:01-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1519154725645_1951052652","id":"20180220-112525_1636082280","dateCreated":"2018-02-20T11:25:25-0800","dateStarted":"2018-02-20T11:26:01-0800","dateFinished":"2018-02-20T11:26:01-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1964"},{"title":"Copy one Cassandra Table to A New Table","text":"// Practice creating new tables from existing Dataframes\n\nval inputData = spark\n  .range(1, 100)\n  .select('id.as(\"k\"), 'id.as(\"c\"), 'id.as(\"v\"))\n  \n//Create a table\nTry(inputData.createCassandraTable(\"test\", \"source\", Some(Seq(\"k\")), Some(Seq(\"c\"))))\n\ninputData\n  .write\n  .cassandraFormat(\"tab\",\"test\")\n  .mode(\"append\")\n  .save()\n\n\n// Your Code Here\n\nspark.read.cassandraFormat(\"destination\", \"test\").load().count == 100 // Should be true :)","user":"anonymous","dateUpdated":"2018-02-20T11:37:30-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1519154343652_-2143579772","id":"20180220-111903_1686365766","dateCreated":"2018-02-20T11:19:03-0800","dateStarted":"2018-02-20T11:36:29-0800","dateFinished":"2018-02-20T11:36:30-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:1965","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"inputData: org.apache.spark.sql.DataFrame = [k: bigint, c: bigint ... 1 more field]\nres102: scala.util.Try[Unit] = Failure(com.datastax.driver.core.exceptions.AlreadyExistsException: Table test.source already exists)\njava.io.IOException: Couldn't find destination.test or any similarly named keyspace and table pairs\n  at com.datastax.spark.connector.cql.Schema$.tableFromCassandra(Schema.scala:358)\n  at org.apache.spark.sql.cassandra.CassandraSourceRelation.<init>(CassandraSourceRelation.scala:46)\n  at org.apache.spark.sql.cassandra.CassandraSourceRelation$.apply(CassandraSourceRelation.scala:287)\n  at org.apache.spark.sql.cassandra.DefaultSource.createRelation(DefaultSource.scala:56)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:307)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:146)\n  ... 58 elided\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1519154391163_1238816","id":"20180220-111951_705527584","dateCreated":"2018-02-20T11:19:51-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1966","text":"// Practice the SQL API\nval sql = \"\"\"Your SQL Here\"\"\"\n\nval df = spark.sql(sql).count == 100","dateUpdated":"2018-02-20T11:36:25-0800","title":"Use SQL to create a Cassandra Dataframe"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1519154907963_-1648432007","id":"20180220-112827_262208189","dateCreated":"2018-02-20T11:28:27-0800","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2151","dateUpdated":"2018-02-20T11:37:48-0800","dateFinished":"2018-02-20T11:35:59-0800","dateStarted":"2018-02-20T11:35:58-0800","title":"Change the number of Partitions used in Spark","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"df: org.apache.spark.sql.DataFrame = [k: int, c: int ... 1 more field]\noriginalPartitionCount: Int = 19\nscala.NotImplementedError: an implementation is missing\n  at scala.Predef$.$qmark$qmark$qmark(Predef.scala:230)\n  ... 58 elided\n"}]},"text":"// Can change the read parameters for a Dataframe reader?\nval df = spark.read.cassandraFormat(\"tab\", \"test\").load\n\nval originalPartitionCount = df.rdd.partitions.size\n\nval df2 = ???\n\nval newPartitionCount = df2.rdd.partitions.size\n\noriginalPartitionCount != newPartitionCount\ndf.count == df2.count"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1519155176945_756246974","id":"20180220-113256_1239096648","dateCreated":"2018-02-20T11:32:56-0800","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2337","text":"val inputData = spark\n  .range(1, 10)\n  .select('id.as(\"k\"))\n  \n// Write inputData to a local file file://something.csv\ninputData.write //??\n// Make a dataframe which reads from this file\nval dfFromFile = spark.read //?? \n// Make a dataframe which reads from our test.source Cassandra table\nval dfFromCassandra = spark.read //??\n// Join them together on column k\nval join = //??\n\njoin.count == 10","dateUpdated":"2018-02-20T11:42:31-0800","dateFinished":"2018-02-20T11:41:53-0800","dateStarted":"2018-02-20T11:41:53-0800","title":"Join Data from a CSV with Data in  Cassandra","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"inputData: org.apache.spark.sql.DataFrame = [k: bigint]\nres131: org.apache.spark.sql.DataFrameWriter[org.apache.spark.sql.Row] = org.apache.spark.sql.DataFrameWriter@4cbcaf82\ndfFromFile: org.apache.spark.sql.DataFrameReader = org.apache.spark.sql.DataFrameReader@7e4775af\ndfFromCassandra: org.apache.spark.sql.DataFrameReader = org.apache.spark.sql.DataFrameReader@31313e0e\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1519155528290_1599538297","id":"20180220-113848_526833318","dateCreated":"2018-02-20T11:38:48-0800","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2637"}],"name":"Spark Cassandra Challenges","id":"2D9MBAUH5","angularObjects":{"2D9MRXK9C:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}